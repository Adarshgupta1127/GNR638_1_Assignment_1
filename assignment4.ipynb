{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll9KXEdsAvGj",
        "outputId": "d66c8b58-d7ff-4fa0-b472-608709387930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with SGD_momentum_0.5\n",
            "Epoch 1, Loss: 3.0441\n",
            "Epoch 2, Loss: 3.0361\n",
            "Epoch 3, Loss: 3.0228\n",
            "Epoch 4, Loss: 2.9900\n",
            "Epoch 5, Loss: 2.8874\n",
            "Epoch 6, Loss: 2.7605\n",
            "Epoch 7, Loss: 2.6620\n",
            "Epoch 8, Loss: 2.5013\n",
            "Epoch 9, Loss: 2.3217\n",
            "Epoch 10, Loss: 2.0962\n",
            "Training Finished. Time taken: 1402.44 seconds\n",
            "\n",
            "Training with SGD_momentum_0.9\n",
            "Epoch 1, Loss: 3.0429\n",
            "Epoch 2, Loss: 2.9819\n",
            "Epoch 3, Loss: 2.7980\n",
            "Epoch 4, Loss: 2.4072\n",
            "Epoch 5, Loss: 2.1596\n",
            "Epoch 6, Loss: 1.7645\n",
            "Epoch 7, Loss: 1.2951\n",
            "Epoch 8, Loss: 0.8999\n",
            "Epoch 9, Loss: 0.5303\n",
            "Epoch 10, Loss: 0.3829\n",
            "Training Finished. Time taken: 113.82 seconds\n",
            "\n",
            "Training with SGD_momentum_0.95\n",
            "Epoch 1, Loss: 3.0455\n",
            "Epoch 2, Loss: 2.9813\n",
            "Epoch 3, Loss: 2.8955\n",
            "Epoch 4, Loss: 2.4198\n",
            "Epoch 5, Loss: 1.9822\n",
            "Epoch 6, Loss: 1.6330\n",
            "Epoch 7, Loss: 1.1495\n",
            "Epoch 8, Loss: 0.9501\n",
            "Epoch 9, Loss: 0.6319\n",
            "Epoch 10, Loss: 0.4969\n",
            "Training Finished. Time taken: 114.09 seconds\n",
            "\n",
            "Training with Adam_default\n",
            "Epoch 1, Loss: 2.9628\n",
            "Epoch 2, Loss: 2.5001\n",
            "Epoch 3, Loss: 1.8350\n",
            "Epoch 4, Loss: 1.3746\n",
            "Epoch 5, Loss: 0.8799\n",
            "Epoch 6, Loss: 0.5708\n",
            "Epoch 7, Loss: 0.3458\n",
            "Epoch 8, Loss: 0.2816\n",
            "Epoch 9, Loss: 0.1188\n",
            "Epoch 10, Loss: 0.1273\n",
            "Training Finished. Time taken: 115.70 seconds\n",
            "\n",
            "Training with Adam_beta1_0.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset_path = \"Images\"\n",
        "img_size = (200, 200)\n",
        "batch_size = 32\n",
        "\n",
        "def load_data(dataset_path, img_size, batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, len(dataset.classes)\n",
        "\n",
        "train_loader, val_loader, num_classes = load_data(dataset_path, img_size, batch_size)\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 25 * 25, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
        "    model.to(device)\n",
        "    loss_history = []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        loss_history.append(epoch_loss)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training Finished. Time taken: {training_time:.2f} seconds\")\n",
        "    return loss_history, training_time\n",
        "\n",
        "optimizer_configs = {\n",
        "    \"SGD\": [\n",
        "        {\"name\": \"SGD_momentum_0.5\", \"class\": optim.SGD, \"params\": {\"lr\": 0.01, \"momentum\": 0.5}},\n",
        "        {\"name\": \"SGD_momentum_0.9\", \"class\": optim.SGD, \"params\": {\"lr\": 0.01, \"momentum\": 0.9}},\n",
        "        {\"name\": \"SGD_momentum_0.95\", \"class\": optim.SGD, \"params\": {\"lr\": 0.01, \"momentum\": 0.95}}\n",
        "    ],\n",
        "    \"Adam\": [\n",
        "        {\"name\": \"Adam_default\", \"class\": optim.Adam, \"params\": {\"lr\": 0.001, \"betas\": (0.9, 0.999)}},\n",
        "        {\"name\": \"Adam_beta1_0.8\", \"class\": optim.Adam, \"params\": {\"lr\": 0.001, \"betas\": (0.8, 0.99)}},\n",
        "        {\"name\": \"Adam_beta2_0.9\", \"class\": optim.Adam, \"params\": {\"lr\": 0.001, \"betas\": (0.95, 0.9)}}\n",
        "    ],\n",
        "    \"RMSprop\": [\n",
        "        {\"name\": \"RMSprop_default\", \"class\": optim.RMSprop, \"params\": {\"lr\": 0.001, \"momentum\": 0.9}}\n",
        "    ],\n",
        "    \"Adagrad\": [\n",
        "        {\"name\": \"Adagrad_default\", \"class\": optim.Adagrad, \"params\": {\"lr\": 0.01}}\n",
        "    ]\n",
        "}\n",
        "\n",
        "loss_histories = {}\n",
        "training_times = {}\n",
        "\n",
        "for opt_group, configs in optimizer_configs.items():\n",
        "    for config in configs:\n",
        "        print(f\"\\nTraining with {config['name']}\")\n",
        "        model = CNN(num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = config[\"class\"](model.parameters(), **config[\"params\"])\n",
        "        loss_history, training_time = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n",
        "        loss_histories[config[\"name\"]] = loss_history\n",
        "        training_times[config[\"name\"]] = training_time\n",
        "\n",
        "def plot_loss_curves(loss_histories, title, keys, epochs=10):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for key in keys:\n",
        "        plt.plot(range(1, epochs + 1), loss_histories[key], label=key)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_loss_curves(loss_histories, \"Loss Curves for SGD with Different Momentum Values\",\n",
        "                 [\"SGD_momentum_0.5\", \"SGD_momentum_0.9\", \"SGD_momentum_0.95\"])\n",
        "\n",
        "\n",
        "plot_loss_curves(loss_histories, \"Loss Curves for Adam with Different Beta Values\",\n",
        "                 [\"Adam_default\", \"Adam_beta1_0.8\", \"Adam_beta2_0.9\"])\n",
        "\n",
        "\n",
        "best_configs = [\"SGD_momentum_0.9\", \"Adam_default\", \"RMSprop_default\", \"Adagrad_default\"]\n",
        "\n",
        "plot_loss_curves(loss_histories, \"Loss Curves for Best Configurations of Each Optimizer\", best_configs)\n",
        "\n",
        "\n",
        "print(\"\\nTraining Times Summary:\")\n",
        "print(\"{:<20} {:<15}\".format(\"Optimizer\", \"Time (seconds)\"))\n",
        "print(\"-\" * 35)\n",
        "for name, t in training_times.items():\n",
        "    print(\"{:<20} {:<15.2f}\".format(name, t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeQ9IkCPDUYe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
